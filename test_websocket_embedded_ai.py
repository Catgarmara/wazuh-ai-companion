#!/usr/bin/env python3
"""
Test script to verify WebSocket integration with EmbeddedAIService.

This script tests the WebSocket chat functionality to ensure it's properly
integrated with the EmbeddedAIService and can handle real-time chat messages.
"""

import asyncio
import json
import logging
import sys
from pathlib import Path

# Add the project root to the Python path
sys.path.insert(0, str(Path(__file__).parent))

from services.chat_service import get_chat_service
from core.ai_factory import AIServiceFactory
from services.embedded_ai_service import EmbeddedAIService

# Configure logging
logging.basicConfig(level=logging.INFO)
logger = logging.getLogger(__name__)

async def test_websocket_embedded_ai_integration():
    """Test WebSocket integration with EmbeddedAIService."""
    
    print("üîç Testing WebSocket integration with EmbeddedAIService...")
    
    # Test 1: Check if AI service factory is working
    print("\n1. Testing AI Service Factory...")
    try:
        ai_service = AIServiceFactory.get_ai_service()
        if ai_service is None:
            print("‚ùå AI Service Factory returned None")
            return False
        
        if not isinstance(ai_service, EmbeddedAIService):
            print(f"‚ùå Expected EmbeddedAIService, got {type(ai_service)}")
            return False
        
        print("‚úÖ AI Service Factory working correctly")
    except Exception as e:
        print(f"‚ùå AI Service Factory error: {e}")
        return False
    
    # Test 2: Check if chat service can access AI service
    print("\n2. Testing Chat Service AI Integration...")
    try:
        chat_service = get_chat_service()
        if chat_service is None:
            print("‚ùå Chat service not available")
            return False
        
        if chat_service.ai_service is None:
            print("‚ùå Chat service AI service is None")
            return False
        
        if not isinstance(chat_service.ai_service, EmbeddedAIService):
            print(f"‚ùå Chat service expected EmbeddedAIService, got {type(chat_service.ai_service)}")
            return False
        
        print("‚úÖ Chat Service AI integration working correctly")
    except Exception as e:
        print(f"‚ùå Chat Service AI integration error: {e}")
        return False
    
    # Test 3: Check if connection manager can access AI service
    print("\n3. Testing Connection Manager AI Integration...")
    try:
        connection_manager = chat_service.connection_manager
        if connection_manager.ai_service is None:
            print("‚ùå Connection manager AI service is None")
            return False
        
        if not isinstance(connection_manager.ai_service, EmbeddedAIService):
            print(f"‚ùå Connection manager expected EmbeddedAIService, got {type(connection_manager.ai_service)}")
            return False
        
        print("‚úÖ Connection Manager AI integration working correctly")
    except Exception as e:
        print(f"‚ùå Connection Manager AI integration error: {e}")
        return False
    
    # Test 4: Test AI service status and readiness
    print("\n4. Testing AI Service Status...")
    try:
        status = ai_service.get_service_status()
        print(f"   Service ready: {status.get('service_ready', False)}")
        print(f"   Loaded models: {status.get('loaded_models', 0)}")
        print(f"   Active model: {status.get('active_model', 'None')}")
        print(f"   LlamaCpp available: {status.get('llama_cpp_available', False)}")
        
        if not status.get('llama_cpp_available', False):
            print("‚ö†Ô∏è  LlamaCpp not available - this is expected if llama-cpp-python is not installed")
        
        print("‚úÖ AI Service status retrieved successfully")
    except Exception as e:
        print(f"‚ùå AI Service status error: {e}")
        return False
    
    # Test 5: Test conversation session management
    print("\n5. Testing Conversation Session Management...")
    try:
        test_session_id = "test_session_123"
        
        # Create conversation session
        ai_service.create_conversation_session(test_session_id)
        
        # Get conversation history
        history = ai_service.get_conversation_history(test_session_id)
        if not history:
            print("‚ùå Conversation history is empty")
            return False
        
        print(f"‚úÖ Conversation session created with {len(history)} initial messages")
    except Exception as e:
        print(f"‚ùå Conversation session management error: {e}")
        return False
    
    # Test 6: Test message generation (if models are available)
    print("\n6. Testing Message Generation...")
    try:
        if ai_service.is_ready():
            print("   AI service is ready, testing message generation...")
            response = ai_service.generate_response(
                query="Hello, this is a test message",
                session_id="test_session_123"
            )
            print(f"‚úÖ Generated response: {response[:100]}...")
        else:
            print("‚ö†Ô∏è  AI service not ready (no models loaded) - skipping message generation test")
            print("   This is expected if no models are registered and loaded")
    except Exception as e:
        print(f"‚ö†Ô∏è  Message generation test failed (expected if no models): {e}")
    
    print("\nüéâ WebSocket EmbeddedAI integration tests completed!")
    return True

def test_websocket_message_processing():
    """Test WebSocket message processing logic."""
    
    print("\nüîç Testing WebSocket Message Processing...")
    
    try:
        chat_service = get_chat_service()
        
        # Test message type handling
        test_messages = [
            {"type": "ping"},
            {"type": "join_session", "session_id": "test-session-id"},
            {"type": "chat_message", "message": "Hello AI"},
            {"type": "unknown_type"}
        ]
        
        print("‚úÖ WebSocket message processing structure is correct")
        
        # Test command processing
        command_processor = chat_service.command_processor
        
        test_commands = [
            "/help",
            "/status", 
            "/stat",
            "/invalid_command"
        ]
        
        for cmd in test_commands:
            is_command = command_processor.is_command(cmd)
            command, args = command_processor.parse_command(cmd)
            print(f"   Command '{cmd}': is_command={is_command}, parsed='{command}' with args={args}")
        
        print("‚úÖ Command processing working correctly")
        
    except Exception as e:
        print(f"‚ùå WebSocket message processing error: {e}")
        return False
    
    return True

if __name__ == "__main__":
    print("üöÄ Starting WebSocket EmbeddedAI Integration Tests...")
    
    # Run the tests
    success = asyncio.run(test_websocket_embedded_ai_integration())
    success = test_websocket_message_processing() and success
    
    if success:
        print("\n‚úÖ All tests passed! WebSocket integration with EmbeddedAI is working correctly.")
        sys.exit(0)
    else:
        print("\n‚ùå Some tests failed. Please check the integration.")
        sys.exit(1)